# Portfolio

---

## Data Science (M.Sc)  
[Resume](/pdf/Lebenslauf_Nhi_Nguyen.pdf) | üìß [Nhi.nguyenpb@gmail.com](mailto:Nhi.nguyenpb@gmail.com)  

## üìù Projekte  
### **Masterarbeit: Deep Learning in EEG Classification**  
[*View Poster*](/pdf/Poster_Masterthesis_NhiNguyen.pdf)

In dieser Masterarbeit wird die Entwicklung **generalisierbarer DL-Modelle** f√ºr die Analyse von **Elektroenzephalographie (EEG)**-Daten untersucht. Ein kleines, repr√§sentatives **Subset** von EEG-Datens√§tzen wurde erstellt, das die **Diversit√§t** einer gr√∂√üeren Sammlung abbildet und so die **Generalisierbarkeit** der Modelle √ºber verschiedene EEG-Dom√§nen hinweg f√∂rdert, ohne dom√§nenspezifische Anpassungen zu ben√∂tigen.

Die Arbeit analysiert **11 End-to-End-DL-Modelle**, die auf **17 EEG-Datens√§tzen** trainiert und getestet wurden. Ein innovativer Ansatz zur Auswahl des Subsets kombiniert **Ridge-Regression** mit **Korrelationsanalysen**, um den **Median-F1-Score** der Modelle basierend auf diesem Subset vorherzusagen. Das final ausgew√§hlte Subset minimiert **Vorhersagefehler**, gew√§hrleistet **Diversit√§t** und vermeidet **Redundanz**.

Die Ergebnisse zeigen, dass kein DL-Modell eine herausragende **Generalisierbarkeit** √ºber alle Datens√§tze aufwies. Das ausgew√§hlte Subset zeigte jedoch geringe **Vorhersageabweichungen** und schwache **Korrelationen**, was seine **Diversit√§t** unterstreicht. Diese Arbeit liefert einen wertvollen **Rahmen** f√ºr die Entwicklung effizienter und **generalisierbarer DL-Modelle** in der **EEG-Klassifikation**.

***Skills***: *Deep Learning (Tensorflow/ Keras), Python, Pandas, Scikit-learn, Feature Engineering, Datenvisualisierung, Projektmanagement.*

![models](/img/ranking_models.png)
*Evaluation von Modellen: Leistung und Generalisierungsf√§higkeit.*

![datasets](/img/Boxplot_datasets.png) 
*Boxplot der Modellleistung √ºber verschiedene Datens√§tze.*

---

### **Data-Analyst- und Data-Science-Projekte** 
**Web Traffic Analysis and Bot Detection**

Analyzed web session data to differentiate between human users and non-human (bot) traffic using rule-based logic. Developed a filtering strategy leveraging metadata features such as user agents, ASN (Autonomous System Number), and behavioral patterns like clickout frequency and hit volume. Built KPIs including Booking Conversion Rate and Clickout Engagement Rate to evaluate session quality before and after bot filtering. Created a data-driven presentation highlighting key insights, traffic anomalies, and actionable recommendations to optimize traffic quality and analytics accuracy.

***Key contributions:***
- Designed transparent, interpretable logic for bot detection using metadata and behavior signals.
- Improved accuracy of engagement KPIs by removing noisy bot sessions.
- Delivered visual and statistical comparisons between human and bot traffic patterns.
- Recommended strategic improvements for web analytics and session tracking.

***Skills***: *Python (NumPy, Pandas , Scikit-learn, Matplotlib, Seaborn)*

***Table***: *Comparison of KPIs Before and After Bot Filtering*

| **Metric**                | **Before Filtering** | **Humans (After Filtering)** | **Bots**   |
|--------------------------|----------------------|------------------------------|------------|
| Avg. Hits/Session        | ‚âà64                  | <span style="color:red">‚âà26 ‚Üì</span>      | ‚âà62    |
| Clickout Engagement Rate | 0.6%                 | <span style="color:green">33% ‚Üë</span>    | 3.7%   |
| Booking Conversion Rate  | 0.7%                 | <span style="color:green">1% ‚Üë</span>     | 0%     |
| Bounce Rate (1-hit)      | 23%                  | <span style="color:red">0.1% ‚Üì</span>     | 67.9%  |

*Filtering bot traffic significantly improves the accuracy of user engagement metrics, distinguishing between real user behavior and automated activity.*

---

**Datenbasierte Analyse zur Optimierung eines Rotweinsortiments**

***Ziel:***  
Identifikation physikalisch-chemischer Eigenschaften, die mit hoher Rotweinqualit√§t zusammenh√§ngen, um fundierte Sortimentsentscheidungen im Handel zu unterst√ºtzen.

***Vorgehen:***  
- Explorative Datenanalyse & Korrelationspr√ºfung  
- Umkodierung der Qualit√§t in zwei Klassen (‚Äûgut‚Äú vs. ‚Äûnicht gut‚Äú)  
- Modellvergleich und Modellbasierte Feature-Importance: Random Forest, Gradient Boosting, SVC, Logistic Regression, KNN
- Ableitung von Schwellenwerten f√ºr die vier wichtigsten Qualit√§tsmerkmale

***Ergebnisse:***  
Hoch bewertete Weine zeichnen sich durch *h√∂heren Alkoholgehalt, niedrige fl√ºchtige S√§ure, moderate Sulfate und geringes Gesamtschwefeldioxid* aus. Diese Merkmale bilden eine objektive Grundlage f√ºr die Sortimentsauswahl.

***Skills***: *Python (pandas, scikit-learn, seaborn), Random Forest, Klassifikation, Feature Importance*

![Rotwein](/img/wine.png)
*Verteilung wichtiger Merkmale nach Weinbewertung (mit 1=nicht gut, 0=gut)*

---

### **Team-Projekt** 
**Produktclustering und Preismodellierung bei Tankstellen**

Im Rahmen dieses Projekts entwickelten wir datengetriebene L√∂sungen zur Optimierung der **Produkterfassung** und **Preismodellierung** an **Tankstellen**. Durch **Produktclustering** mittels **Konfidenzintervallen** reduzierten wir den Erfassungsaufwand um durchschnittlich **41,1%**, w√§hrend wir die Genauigkeit beibehielten. F√ºr die **Preismodellierung** nutzten wir **Gradient Boosting** und **SHAP-Werte**, um die Preisbildung zu analysieren und zu erkl√§ren, und erzielten eine signifikante Verbesserung gegen√ºber linearen Modellen. **Datenvorverarbeitung** und **Feature Engineering**, einschlie√ülich der Integration von **Geodaten**, waren entscheidend f√ºr den Erfolg. Die Ergebnisse erm√∂glichen es der Firma, Kosten zu senken, wertvolle Einblicke in die Preisgestaltung zu gewinnen und ihre Prozesse zu optimieren. 

***Skills***: *Python, Pandas, Scikit-learn, XGBoost, SHAP, statistische Analyse, Datenvisualisierung, Projektmanagement.*

![werdenktwas](/img/werdenktwas.png)
*Ein Beispiel der Einsparung mithilfe der Produktclustering durch √§hnliche Preisstrukturen*

---

### **Recommendation System** 
**Buch-Empfehlungssystem**

Dieses Projekt zielt darauf ab, ein intelligentes Empfehlungssystem f√ºr B√ºcher zu entwickeln, das auf den Interessen √§hnlicher Nutzer:innen basiert (**Collaborative Filtering**). Die wichtigsten Schritte:

- Parsing von Buch-Metadaten
- Erstellung einer Suchmaschine zur gezielten Buchsuche  
- Identifikation von Nutzer:innen mit √§hnlichen Leseinteressen**  
- Analyse der B√ºcher, die diesen Nutzer:innen gefallen haben  
- Generierung und Verbesserung der Empfehlungen durch Collaborative Filtering  

***Skills***: *Python (NumPy, Pandas , Scikit-learn, Matplotlib), Text Similarity Analysis, NLP (Tokenization, Tfidf)*

![BookRecommendations](/img/bookrec.png)
*Ergebnis von Buch-Empfehlungssystem mit Collaborative Filtering*

---

### **Computer Vision** 
**Qualit√§tssicherung von Inbusschl√ºsseln**

In diesem Projekt wurde ein **Computer-Vision-Programm** entwickelt, das automatisch die **Ma√üe von Inbusschl√ºsseln** erfasst und im Bild erg√§nzt. Ziel war es, eine **kosteng√ºnstige und pr√§zise Alternative** zur manuellen Qualit√§tskontrolle bereitzustellen. Das System erkennt die Werkzeuge **zuverl√§ssig** und misst deren **Abmessungen in Millimetern**. Es ist **robust** gegen√ºber leichten Schatten, Bildrauschen und Variationen in der Beleuchtung. Die **Genauigkeit der Messung** wurde anhand realer Objekte √ºberpr√ºft und zeigte eine **geringe Abweichung** zu manuellen Messungen.

***Skills***: *Python (NumPy, Pandas, OpenCV, Matplotlib), Feature Extraction, Bildverarbeitung, Objekterkennung, Datenauswertung.*

![Ausgemessene Inbusschl√ºsseln](/img/cv_inbusschl√ºsseln.png)
*Ausgemessene Inbusschl√ºsseln im Bild.*

---

**Deep Learning zur automatisierten Vogelartenklassifikation**

In diesem Projekt wurde ein **Convolutional Neural Network (CNN)** zur Klassifikation von **524 Vogelarten** entwickelt. Um die Trainingsdaten zu erweitern, wurden verschiedene **Augmentierungstechniken** wie Anpassung von **S√§ttigung** und **Kontrast** sowie **Rotation** und **horizontales Spiegeln** angewendet.

Durch **Hyperparameter-Optimierung** wurde ein Modell mit **f√ºnf Schichten** gefunden, das eine **Genauigkeit von 89 %** erreichte. Mithilfe von **Grad-CAM-Visualisierungen** wurde die **Erkl√§rbarkeit** der Modellentscheidungen analysiert. Dabei zeigte sich, dass das CNN oft **Schnabel**, **Augen** oder auff√§llige **Farb√ºberg√§nge** zur Klassifikation heranzieht. Dies f√ºhrte gelegentlich zu Fehlklassifikationen, wenn nur ein einzelnes **Merkmal** betrachtet wurde. Das Projekt zeigt, dass bereits mit wenigen **Schichten** ein leistungsstarker **Klassifikator** entwickelt werden kann.

***Skills***: *Python (NumPy, Pandas, TensorFlow, OpenCV, Matplotlib), CNN, Grad-CAM, GitLab f√ºr Versionskontrolle, Statistische Evaluierung der Modellleistung,  Ergebnisvisualisierung.*

![Korrekt klassifizierter Vogel](/img/cv_vogel.png)
*Korrekt klassifizierter Vogel.*

![Falsch klassifizierter Vogel](/img/cv_vogel2.png)
*Falsch klassifizierter Vogel*

---

### **Natural Language Processing** 
**Analyse von Nachrichtenartikeln mit NLP und Web Scraping**  

Im Rahmen diese Projekts wurde einen Webcrawler entwickelt, der 1182 Artikel von *n-tv.de* heruntergeladen und in einer SQLite-Datenbank gespeichert hat. Die gesammelten Daten wurden mithilfe von NLP-Techniken analysiert, um Kategorisierungen, Wortverteilungen und Topic-Clustering zu untersuchen.  

**Hauptmethoden und Ergebnisse:**  
- **Web Scraping & Datenverarbeitung:** Extraktion von Kategorien via XPath und RegEx, Speicherung der Artikeltexte in einer Datenbank.  
- **Textanalyse:** Tokenisierung, Lemmatisierung und Berechnung der Worth√§ufigkeiten ergaben eine Gesamtlexikongr√∂√üe von 92.475 W√∂rtern, die durch Vorverarbeitung auf 78.055 reduziert wurde.  
- **√Ñhnlichkeitsanalyse:** Berechnung von Term Frequency (TF), Inverse Document Frequency (IDF) sowie Kosinus- und Sinus√§hnlichkeiten zur Dokumentklassifikation. Dabei zeigte sich, dass Wirtschaftsartikel stark durch Begriffe wie ‚ÄûProzent‚Äú oder ‚ÄûEuro‚Äú dominiert wurden.  
- **Topic Modeling:** Nutzung von *Latent Dirichlet Allocation (LDA)* und *BERTopic* zur automatisierten Themenextraktion. Dabei konnten Themen aus den Bereichen Wirtschaft und Gesellschaft identifiziert werden, wobei sich Cluster teilweise √ºberlappten.  

Die Analyse zeigte, dass klassische Kategorien aus der URL nicht immer die tats√§chlichen thematischen Schwerpunkte widerspiegeln. Verbesserungen k√∂nnten durch eine feinere Kategorisierung oder alternative Klassifikationsmethoden erzielt werden.

***Skills***: *Web Scraping (XPath, RegEx, BeautifulSoup, Scrapy) , Database Management (SQLite, SQL queries), NLP (Tokenization, Lemmatisation, Stopword Removal, TF-IDF), Text Similarity Analysis, Topic Modeling (LDA, BERTopic), Data Analysis (Scikit-learn, Gensim, Pandas, NumPy), Data Visualization (Matplotlib, Seaborn, Plotly), Clustering & Classification (k-Means, Neural Topic Model)*

![Clustering](/img/topic-clustering.png)
*BERTopic Modell f√ºr den ntv.de Datensatz.*


